{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d6e9f4",
   "metadata": {},
   "source": [
    "# AIM301 - Build an advanced RAG assistant with Amazon Bedrock\n",
    "\n",
    "Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured solely by the parametric knowledge they encapsulate. Although Retrieval Augmented Generation (RAG) is a practicable complement to LLMs, it relies heavily on the relevance of retrieved documents, raising concerns about how the model behaves if retrieval goes wrong.\n",
    "\n",
    "Advanced RAG techniques like [Corrective RAG](https://arxiv.org/pdf/2401.15884.pdf)(CRAG) were proposed to improve the robustness of generation. In CRAG, a lightweight retrieval evaluator is designed to assess the overall quality of retrieved documents for a query, returning a confidence degree based on which different knowledge retrieval actions can be triggered. Since retrieval from static and limited corpora can only return sub-optimal documents, large-scale web searches are utilized as an extension for augmenting the retrieval results.\n",
    "\n",
    "This notebook will walk you through the process of building a simplified CRAG based assistant using a Large Language Model (LLM) hosted on [Amazon Bedrock](https://aws.amazon.com/bedrock/). We will also use [Knowledge Bases for Amazon Bedrock](https://aws.amazon.com/bedrock/knowledge-bases/) and [Agents for Amazon Bedrock](https://aws.amazon.com/bedrock/agents/).\n",
    "\n",
    "We will use [LangChain](https://www.langchain.com/) to simplify the process of constructing the prompts, interacting with the LLMs and Knowledge Bases (KBs). In the process of working through this notebook, you will learn how to setup the Amazon Bedrock client environment, configure security permissions and use prompt templates in LangChain. Invocations that involve LangChain will be explicitly mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe0424",
   "metadata": {},
   "source": [
    "![](./images/flowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0111293",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>\n",
    "    <ul>\n",
    "        <li>This notebook should only be run from within an <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html\">Amazon SageMaker Notebook instance</a> or within an <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated.html\">Amazon SageMaker Studio Notebook</a>.</li>\n",
    "        <li>This notebook uses text based models along with their versions that were available at the time of writing. Update these as required.</li>\n",
    "        <li>At the time of writing this notebook, Amazon Bedrock was only available in <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-regions.html\">these supported AWS Regions</a>. If you are running this notebook from any other AWS Region, then you have to change the Amazon Bedrock client's region and/or endpoint URL parameters to one of those supported AWS Regions that has Anthropic Claude 3. Follow the guidance in the <i>Organize imports</i> section of this notebook.</li>\n",
    "        <li>This notebook is recommended to be run with a minimum instance size of <i>ml.t3.medium</i> and\n",
    "            <ul>\n",
    "                <li>With <i>Amazon Linux 2, Jupyter Lab 3</i> as the platform identifier on an Amazon SageMaker Notebook instance.</li>\n",
    "                <li> (or)\n",
    "                <li>With <i>Data Science 3.0</i> as the image on an Amazon SageMaker Studio Notebook.</li>\n",
    "            <ul>\n",
    "        </li>\n",
    "        <li>At the time of this writing, the most relevant latest version of the Kernel for running this notebook,\n",
    "            <ul>\n",
    "                <li>On an Amazon SageMaker Notebook instance was <i>conda_python3</i></li>\n",
    "                <li>On an Amazon SageMaker Studio Notebook was <i>Python 3</i></li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e88d20",
   "metadata": {},
   "source": [
    "**Table of Contents:**\n",
    "\n",
    "1. [Complete prerequisites](#Complete%20prerequisites)\n",
    "\n",
    "    1. [Check and configure access to the Internet](#Check%20and%20configure%20access%20to%20the%20Internet)\n",
    "\n",
    "    2. [Install required software libraries](#Install%20required%20software%20libraries)\n",
    "    \n",
    "    3. [Configure logging](#Configure%20logging)\n",
    "        \n",
    "        1. [System logs](#Configure%20system%20logs)\n",
    "        \n",
    "        2. [Application logs](#Configure%20application%20logs)\n",
    "    \n",
    "    4. [Organize imports](#Organize%20imports)\n",
    "    \n",
    "    5. [Create common objects](#Create%20common%20objects)\n",
    "    \n",
    "    6. [Enable model access in Amazon Bedrock](#Enable%20model%20access%20in%20Amazon%20Bedrock)\n",
    "    \n",
    "    7. [Check and configure security permissions](#Check%20and%20configure%20security%20permissions)\n",
    "    \n",
    "    8. [Create common objects](#Create%20common%20objects)\n",
    "    \n",
    "    9. [Get Knowledge Base details](#Get%20Knowledge%20Base%20details)\n",
    "    \n",
    "    10. [Get Bedrock Agent details](#Get%20Bedrock%20Agent%20details)\n",
    "\n",
    " 2. [Load data to Knowledge Base](#Load%20data%20to%20Knowledge%20Base)\n",
    " \n",
    "    1. [Step0a: Download data](#Load%20to%20KB%20Step0a)\n",
    "    \n",
    "    2. [Step0b: Copy downloaded data to S3](#Load%20to%20KB%20Step0b)\n",
    "    \n",
    "    3. [Steps 0c to 0e: Sync to Knowledge Base](#Load%20to%20KB%20Steps0c%20to%200e)\n",
    " \n",
    " 3. [Scenario 1 - match found in KB](#Match%20found%20in%20KB)\n",
    " \n",
    "     1. [Step 1: User query](#Scenario%201%20Step%201)\n",
    "     \n",
    "     2. [Steps 2a and 2b: Query lookup](#Scenario%201%20Steps%202a%20and%202b)\n",
    "     \n",
    "     3. [Steps 3a and 3b: Determine the query results relevancy](#Scenario%201%20Steps%203a%20and%203b)\n",
    "     \n",
    "     4. [Steps 4a through 5: Process to completion](#Scenario%201%20Steps%204a%20through%205)\n",
    " \n",
    " 4. [Scenario 2 - match not found in KB](#Match%20not%20found%20in%20KB)\n",
    " \n",
    "     1. [Step 1: User query](#Scenario%202%20Step%201)\n",
    "     \n",
    "     2. [Steps 2a and 2b: Query lookup](#Scenario%202%20Steps%202a%20and%202b)\n",
    "     \n",
    "     3. [Steps 3a and 3b: Determine the query results relevancy](#Scenario%202%20Steps%203a%20and%203b)\n",
    "     \n",
    "     4. [Steps 4a through 7: Process to completion](#Scenario%202%20Steps%204a%20through%207)\n",
    " \n",
    " 5. [Cleanup](#Cleanup)\n",
    " \n",
    " 6. [Conclusion](#Conclusion)\n",
    " \n",
    " 7. [Frequently Asked Questions (FAQs)](#FAQs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9fb9d3",
   "metadata": {},
   "source": [
    "##  1. Complete prerequisites <a id ='Complete%20prerequisites'> </a>\n",
    "\n",
    "Check and complete the prerequisites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85c39b",
   "metadata": {},
   "source": [
    "###  A. Check and configure access to the Internet <a id ='Check%20and%20configure%20access%20to%20the%20Internet'> </a>\n",
    "This notebook requires outbound access to the Internet to download the required software updates and to download the dataset.  You can either provide direct Internet access (default) or provide Internet access through an [Amazon VPC](https://aws.amazon.com/vpc/).  For more information on this, refer [here](https://docs.aws.amazon.com/sagemaker/latest/dg/appendix-notebook-and-internet-access.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820efd56",
   "metadata": {},
   "source": [
    "### B. Install required software libraries <a id ='Install%20required%20software%20libraries'> </a>\n",
    "This notebook requires the following libraries:\n",
    "* [SageMaker Python SDK version 2.x](https://sagemaker.readthedocs.io/en/stable/v2.html)\n",
    "* [Python 3.10.x](https://www.python.org/downloads/release/python-3100/)\n",
    "* [Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)\n",
    "* [LangChain](https://www.langchain.com/)\n",
    "\n",
    "Run the following cell to install the required libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb373af",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">  \n",
    "    <b>Note:</b> At the end of the installation, the Kernel will be forcefully restarted immediately. Please wait 10 seconds for the kernel to come back before running the next cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7256d4fc-0361-4cee-a548-d9b7e355824f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting boto3==1.34.89\n",
      "  Downloading boto3-1.34.89-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.89 (from boto3==1.34.89)\n",
      "  Downloading botocore-1.34.90-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from boto3==1.34.89) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from boto3==1.34.89) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.89->boto3==1.34.89) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.89->boto3==1.34.89) (1.26.15)\n",
      "Requirement already satisfied: six>=1.5 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.89->boto3==1.34.89) (1.16.0)\n",
      "Downloading boto3-1.34.89-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.90-py3-none-any.whl (12.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.74\n",
      "    Uninstalling botocore-1.34.74:\n",
      "      Successfully uninstalled botocore-1.34.74\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.74\n",
      "    Uninstalling boto3-1.34.74:\n",
      "      Successfully uninstalled boto3-1.34.74\n",
      "Successfully installed boto3-1.34.89 botocore-1.34.90\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting langchain==0.1.16\n",
      "  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langchain==0.1.16) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langchain==0.1.16) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langchain==0.1.16) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langchain==0.1.16) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langchain==0.1.16) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langchain==0.1.16) (1.33)\n",
      "Collecting langchain-community<0.1,>=0.0.32 (from langchain==0.1.16)\n",
      "  Downloading langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain==0.1.16)\n",
      "  Downloading langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langchain==0.1.16) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langchain==0.1.16) (0.1.38)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langchain==0.1.16) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langchain==0.1.16) (2.5.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langchain==0.1.16) (2.29.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langchain==0.1.16) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.16) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain==0.1.16) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (3.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.16) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.1 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.16) (2.14.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.16) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.16) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.16) (3.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.16) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.16) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.16) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (1.0.0)\n",
      "Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.45-py3-none-any.whl (291 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m200.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain-core, langchain-community, langchain\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.37\n",
      "    Uninstalling langchain-core-0.1.37:\n",
      "      Successfully uninstalled langchain-core-0.1.37\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.29\n",
      "    Uninstalling langchain-community-0.0.29:\n",
      "      Successfully uninstalled langchain-community-0.0.29\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.13\n",
      "    Uninstalling langchain-0.1.13:\n",
      "      Successfully uninstalled langchain-0.1.13\n",
      "Successfully installed langchain-0.1.16 langchain-community-0.0.34 langchain-core-0.1.45\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting requests==2.31.0\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from requests==2.31.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from requests==2.31.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from requests==2.31.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from requests==2.31.0) (2024.2.2)\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: requests\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.29.0\n",
      "    Uninstalling requests-2.29.0:\n",
      "      Successfully uninstalled requests-2.29.0\n",
      "Successfully installed requests-2.31.0\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting sagemaker==2.216.1\n",
      "  Downloading sagemaker-2.216.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from sagemaker==2.216.1) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.33.3 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from sagemaker==2.216.1) (1.34.89)\n",
      "Collecting cloudpickle==2.2.1 (from sagemaker==2.216.1)\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting google-pasta (from sagemaker==2.216.1)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from sagemaker==2.216.1) (1.26.4)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from sagemaker==2.216.1) (4.25.3)\n",
      "Collecting smdebug-rulesconfig==1.0.1 (from sagemaker==2.216.1)\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker==2.216.1)\n",
      "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from sagemaker==2.216.1) (23.2)\n",
      "Requirement already satisfied: pandas in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from sagemaker==2.216.1) (2.2.1)\n",
      "Collecting pathos (from sagemaker==2.216.1)\n",
      "  Downloading pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting schema (from sagemaker==2.216.1)\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from sagemaker==2.216.1) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from sagemaker==2.216.1) (4.21.1)\n",
      "Requirement already satisfied: platformdirs in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from sagemaker==2.216.1) (4.2.0)\n",
      "Collecting tblib<4,>=1.7.0 (from sagemaker==2.216.1)\n",
      "  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from sagemaker==2.216.1) (1.26.15)\n",
      "Requirement already satisfied: requests in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from sagemaker==2.216.1) (2.31.0)\n",
      "Collecting docker (from sagemaker==2.216.1)\n",
      "  Downloading docker-7.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: tqdm in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from sagemaker==2.216.1) (4.66.2)\n",
      "Requirement already satisfied: psutil in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from sagemaker==2.216.1) (5.9.8)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.89 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker==2.216.1) (1.34.90)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker==2.216.1) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker==2.216.1) (0.10.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.216.1) (3.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from requests->sagemaker==2.216.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from requests->sagemaker==2.216.1) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from requests->sagemaker==2.216.1) (2024.2.2)\n",
      "Requirement already satisfied: six in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from google-pasta->sagemaker==2.216.1) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from jsonschema->sagemaker==2.216.1) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from jsonschema->sagemaker==2.216.1) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from jsonschema->sagemaker==2.216.1) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from pandas->sagemaker==2.216.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from pandas->sagemaker==2.216.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/privisaa/opt/anaconda3/envs/langchain_p310/lib/python3.10/site-packages (from pandas->sagemaker==2.216.1) (2024.1)\n",
      "Collecting ppft>=1.7.6.8 (from pathos->sagemaker==2.216.1)\n",
      "  Downloading ppft-1.7.6.8-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dill>=0.3.8 (from pathos->sagemaker==2.216.1)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pox>=0.3.4 (from pathos->sagemaker==2.216.1)\n",
      "  Downloading pox-0.3.4-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting multiprocess>=0.70.16 (from pathos->sagemaker==2.216.1)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting contextlib2>=0.5.5 (from schema->sagemaker==2.216.1)\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Downloading sagemaker-2.216.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m132.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathos-0.3.2-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pox-0.3.4-py3-none-any.whl (29 kB)\n",
      "Downloading ppft-1.7.6.8-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tblib, smdebug-rulesconfig, ppft, pox, importlib-metadata, google-pasta, dill, contextlib2, cloudpickle, schema, multiprocess, docker, pathos, sagemaker\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 7.0.0\n",
      "    Uninstalling importlib-metadata-7.0.0:\n",
      "      Successfully uninstalled importlib-metadata-7.0.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.7\n",
      "    Uninstalling dill-0.3.7:\n",
      "      Successfully uninstalled dill-0.3.7\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.15\n",
      "    Uninstalling multiprocess-0.70.15:\n",
      "      Successfully uninstalled multiprocess-0.70.15\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.14.7 requires dill<0.3.8,>=0.3.0, but you have dill 0.3.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cloudpickle-2.2.1 contextlib2-21.6.0 dill-0.3.8 docker-7.0.0 google-pasta-0.2.0 importlib-metadata-6.11.0 multiprocess-0.70.16 pathos-0.3.2 pox-0.3.4 ppft-1.7.6.8 sagemaker-2.216.1 schema-0.7.5 smdebug-rulesconfig-1.0.1 tblib-3.0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install boto3==1.34.89\n",
    "!pip install langchain==0.1.16\n",
    "!pip install requests==2.31.0\n",
    "!pip install sagemaker==2.216.1\n",
    "\n",
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3c44f",
   "metadata": {},
   "source": [
    "### C. Configure logging <a id ='Configure%20logging'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5ee37",
   "metadata": {},
   "source": [
    "####  a. System logs <a id='Configure%20system%20logs'></a>\n",
    "\n",
    "System logs refers to the logs generated by the notebook's interactions with the underlying notebook instance. Some examples of these are the logs generated when loading or saving the notebook.\n",
    "\n",
    "These logs are automatically setup when the notebook instance is launched.\n",
    "\n",
    "These logs can be accessed through the [Amazon CloudWatch Logs](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html) console in the same AWS Region where this notebook is running.\n",
    "* When running this notebook in an Amazon SageMaker Notebook instance, navigate to the following location,\n",
    "    * <i>CloudWatch > Log groups > /aws/sagemaker/NotebookInstances > {notebook-instance-name}/jupyter.log</i>\n",
    "* When running this notebook in an Amazon SageMaker Studio Notebook, navigate to the following locations,\n",
    "    * <i>CloudWatch > Log groups > /aws/sagemaker/studio > {sagmaker-domain-name}/{user-name}/KernelGateway/{notebook-instance-name}</i>\n",
    "    * <i>CloudWatch > Log groups > /aws/sagemaker/studio > {sagmaker-domain-name}/{user-name}/JupyterServer/default</i>\n",
    "\n",
    "Run the following cell to print the name of the underlying notebook instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c99c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "notebook_name = ''\n",
    "resource_metadata_path = '/opt/ml/metadata/resource-metadata.json'\n",
    "with open(resource_metadata_path, 'r') as metadata:\n",
    "    notebook_name = (json.load(metadata))['ResourceName']\n",
    "print(\"Notebook instance name: '{}'\".format(notebook_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc0025",
   "metadata": {},
   "source": [
    "####  b. Application logs <a id='Configure%20application%20logs'></a>\n",
    "\n",
    "Application logs refers to the logs generated by running the various code cells in this notebook. To set this up, instantiate the [Python logging service](https://docs.python.org/3/library/logging.html) by running the following cell. You can configure the default log level and format as required.\n",
    "\n",
    "By default, this notebook will only print the logs to the corresponding cell's output console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf96e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# Set the logging level and format\n",
    "log_level = logging.INFO\n",
    "log_format = '%(asctime)s - %(levelname)s - %(message)s'\n",
    "logging.basicConfig(level=log_level, format=log_format)\n",
    "\n",
    "# Save these in the environment variables for use in the helper scripts\n",
    "os.environ['LOG_LEVEL'] = str(log_level)\n",
    "os.environ['LOG_FORMAT'] = log_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3bb063",
   "metadata": {},
   "source": [
    "###  D. Organize imports <a id ='Organize%20imports'> </a>\n",
    "\n",
    "Organize all the library and module imports for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "764a06b9-812c-4dad-a652-1cb34aa9d8b7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 13:50:45,182 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/privisaa/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import langchain\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "from botocore.config import Config\n",
    "\n",
    "# Import the helper functions from the 'scripts' folder\n",
    "sys.path.append(os.path.join(os.getcwd(), \"scripts\"))\n",
    "#logging.info(\"Updated sys.path: {}\".format(sys.path))\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ba26b",
   "metadata": {},
   "source": [
    "Print the installed versions of some of the important libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb23f2d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 13:50:46,747 - INFO - Python version : 3.10.14 (main, Mar 21 2024, 11:24:58) [Clang 14.0.6 ]\n",
      "2024-04-24 13:50:46,748 - INFO - Boto3 version : 1.34.89\n",
      "2024-04-24 13:50:46,748 - INFO - SageMaker Python SDK version : 2.216.1\n",
      "2024-04-24 13:50:46,749 - INFO - LangChain version : 0.1.16\n",
      "2024-04-24 13:50:46,750 - INFO - Requests version : 2.31.0\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Python version : {}\".format(sys.version))\n",
    "logging.info(\"Boto3 version : {}\".format(boto3.__version__))\n",
    "logging.info(\"SageMaker Python SDK version : {}\".format(sagemaker.__version__))\n",
    "logging.info(\"LangChain version : {}\".format(langchain.__version__))\n",
    "logging.info(\"Requests version : {}\".format(requests.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f63309",
   "metadata": {},
   "source": [
    "###  E. Set AWS Region and boto3 config <a id ='Set%20AWS%20Region%20and%20boto3%20config'> </a>\n",
    "\n",
    "Get the current AWS Region (where this notebook is running) and the SageMaker Session. These will be used to initialize some of the clients to AWS services using the boto3 APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a746eb15",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">  \n",
    "<b>Note:</b> All the AWS services used by this notebook except Amazon Bedrock will use the current AWS Region. For Bedrock, follow the guidance in the next cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de7be30",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">  \n",
    "<b>Note:</b> At the time of writing this notebook, Amazon Bedrock was only available in <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-regions.html\">these supported AWS Regions</a>. If you are running this notebook from any other AWS Region, then you have to change the Amazon Bedrock client's region and/or endpoint URL parameters to one of those supported AWS Regions that has Anthropic Claude 3. In order to do this, this notebook will use the value specified in the environment variable named <mark>AMAZON_BEDROCK_REGION</mark>. If this is not specified, then the notebook will default to <mark>us-west-2 (Oregon)</mark> for Amazon Bedrock.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a6cb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 20:33:15,394 - INFO - SageMaker Session: Session(region_name='us-east-1')\n",
      "2024-04-25 20:33:15,408 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2024-04-25 20:33:16,474 - WARNING - Couldn't call 'get_role' to get Role ARN from role name ijp-user to get Role path.\n",
      "2024-04-25 20:33:16,476 - INFO - Notebook IAM Role: arn:aws:iam::107465544796:role/service-role/AmazonSageMaker-ExecutionRole-20230502T142709\n",
      "2024-04-25 20:33:16,477 - INFO - Current AWS Region: us-east-1\n",
      "2024-04-25 20:33:16,477 - INFO - AWS Region for Amazon Bedrock: us-west-2\n"
     ]
    }
   ],
   "source": [
    "# Get the AWS Region, SageMaker Session and IAM Role references\n",
    "my_session = boto3.session.Session()\n",
    "logging.info(\"SageMaker Session: {}\".format(my_session))\n",
    "try:\n",
    "    my_iam_role = sagemaker.get_execution_role()\n",
    "except:\n",
    "    my_iam_role = \"arn:aws:iam::107465544796:role/service-role/AmazonSageMaker-ExecutionRole-20230502T142709\"\n",
    "logging.info(\"Notebook IAM Role: {}\".format(my_iam_role))\n",
    "my_region = my_session.region_name\n",
    "logging.info(\"Current AWS Region: {}\".format(my_region))\n",
    "\n",
    "# Explicity set the AWS Region for Amazon Bedrock clients\n",
    "AMAZON_BEDROCK_DEFAULT_REGION = \"us-west-2\"\n",
    "br_region = os.environ.get('AMAZON_BEDROCK_REGION')\n",
    "if br_region is None:\n",
    "    br_region = AMAZON_BEDROCK_DEFAULT_REGION\n",
    "elif len(br_region) == 0:\n",
    "    br_region = AMAZON_BEDROCK_DEFAULT_REGION\n",
    "logging.info(\"AWS Region for Amazon Bedrock: {}\".format(br_region))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8484fc",
   "metadata": {},
   "source": [
    "Set the timeout and retry configurations that will be applied to all the boto3 clients used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "037155d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the standard time out limits in the boto3 client from 1 minute to 3 minutes\n",
    "# and set the retry limits\n",
    "my_boto3_config = Config(\n",
    "    connect_timeout = (60 * 3),\n",
    "    read_timeout = (60 * 3),\n",
    "    retries = {\n",
    "        'max_attempts': 10,\n",
    "        'mode': 'standard'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f0e97",
   "metadata": {},
   "source": [
    "###  F. Enable model access in Amazon Bedrock <a id ='Enable%20model%20access%20in%20Amazon%20Bedrock'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e84ba9d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Note:</b> Before proceeding further with this notebook, you must enable access to the Anthropic Claude 3 models on Amazon Bedrock by following the instructions <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html\">here</a>. You need to submit the use case details. Otherwise, you will get an authorization error.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed57899f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">  \n",
    "<b>Note:</b> You will have to do this manually after reading the End User License Agreement (EULA) for each of the models that you want to enable. Unless you explicitly disable it, this is a one-time setup for each model in an AWS account.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19de160b",
   "metadata": {},
   "source": [
    "Run the following cell to print the Amazon Bedrock model access page URL for the AWS Region that was selected earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78213222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 20:51:35,895 - INFO - Amazon Bedrock model access page - https://us-west-2.console.aws.amazon.com/bedrock/home?region=us-west-2#/modelaccess\n"
     ]
    }
   ],
   "source": [
    "# Print the Amazon Bedrock model access page URL\n",
    "logging.info(\"Amazon Bedrock model access page - https://{}.console.aws.amazon.com/bedrock/home?region={}#/modelaccess\"\n",
    "             .format(br_region, br_region))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c09b6c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">  \n",
    "<b>Note:</b> For running this notebook, you need access to only the Anthropic Claude 3 models. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2ee077",
   "metadata": {},
   "source": [
    "###  G. Check and configure security permissions <a id ='Check%20and%20configure%20security%20permissions'> </a>\n",
    "This notebook uses the IAM role attached to the underlying notebook instance.  To view the name of this role, run the following cell.\n",
    "\n",
    "This IAM role should have the following permissions,\n",
    "\n",
    "1. Full access to invoke Large Language Models (LLMs) on Amazon Bedrock.\n",
    "2. Full access to use Knowledge Bases for Amazon Bedrock.\n",
    "3. Full access to use Agents for Amazon Bedrock.\n",
    "4. Full access to read and write to the Amazon OpenSearch Serverless collection associated with the Knowledge Base.\n",
    "5. Full access to read and write to the Amazon S3 bucket associated with the Knowledge Base.\n",
    "6. Full access to read, write and invoke the AWS Lambda function associated with the Agent.\n",
    "7. Access to write to Amazon CloudWatch Logs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9688f610",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>  During the AIM301 session, by default, all these permissions will be setup.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16baab7",
   "metadata": {},
   "source": [
    "Run the following cell to print the details of the IAM role attached to the underlying notebook instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c64186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 20:51:43,539 - INFO - This notebook's IAM role is 'arn:aws:iam::107465544796:role/service-role/AmazonSageMaker-ExecutionRole-20230502T142709'\n",
      "2024-04-25 20:51:43,541 - INFO - Details of this IAM role are available at https://us-east-1.console.aws.amazon.com/iamv2/home?region=us-east-1#/roles/details/AmazonSageMaker-ExecutionRole-20230502T142709?section=permissions\n"
     ]
    }
   ],
   "source": [
    "# Print the IAM role ARN and console URL\n",
    "logging.info(\"This notebook's IAM role is '{}'\".format(my_iam_role))\n",
    "arn_parts = my_iam_role.split('/')\n",
    "logging.info(\"Details of this IAM role are available at https://{}.console.aws.amazon.com/iamv2/home?region={}#/roles/details/{}?section=permissions\"\n",
    "             .format(my_region, my_region, arn_parts[len(arn_parts) - 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12579ad7",
   "metadata": {},
   "source": [
    "###  H. Create common objects <a id='Create%20common%20objects'></a>\n",
    "\n",
    "To begin with, create the Bedrock clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "124b256c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 20:51:46,899 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "# Create the Amazon S3 client\n",
    "s3_client = boto3.client(\"s3\", region_name = br_region, config = my_boto3_config)\n",
    "\n",
    "# Create the Amazon OpenSearch Serverless client\n",
    "aoss_client = boto3.client(\"opensearchserverless\", region_name = br_region, config = my_boto3_config)\n",
    "\n",
    "# Create the Amazon Bedrock client\n",
    "bedrock_client = boto3.client(\"bedrock\", region_name = br_region, endpoint_url = \"https://bedrock.{}.amazonaws.com\"\n",
    "                              .format(br_region), config = my_boto3_config)\n",
    "\n",
    "# Create the Amazon Bedrock runtime client\n",
    "bedrock_rt_client = boto3.client(\"bedrock-runtime\", region_name = br_region, config = my_boto3_config)\n",
    "\n",
    "# Create the Agents for Amazon Bedrock client\n",
    "bedrock_agt_client = boto3.client(\"bedrock-agent\", region_name = br_region, config = my_boto3_config)\n",
    "\n",
    "# Create the Agents for Amazon Bedrock runtime client\n",
    "bedrock_agt_rt_client = boto3.client(\"bedrock-agent-runtime\", region_name = br_region, config = my_boto3_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900c771e",
   "metadata": {},
   "source": [
    "List all Anthropic Claude 3 LLMs on Amazon Bedrock that are offered through the On-Demand throughput pricing model. This will help you pick the model-ids that you will use further down in this notebook.\n",
    "\n",
    "For more information on this, refer [here](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html#model-ids-arns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "323e08e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 20:51:49,657 - INFO - Displaying available Anthropic Claude 3 models in the 'us-west-2' Region:\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Provider Name   Model Name                     Input Modalities     Output Modalities    Model Id                                -----------------------------------------------------------------------------------------------------------------------------\n",
      "Anthropic       Claude 3 Sonnet                TEXT|IMAGE           TEXT                 anthropic.claude-3-sonnet-20240229-v1:0 \n",
      "Anthropic       Claude 3 Haiku                 TEXT|IMAGE           TEXT                 anthropic.claude-3-haiku-20240307-v1:0  -----------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note: 'print_claude_3_llm_info' available through ./scripts/helper_functions.py\n",
    "print_claude_3_llm_info(bedrock_client, 'ON_DEMAND')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b1322f",
   "metadata": {},
   "source": [
    "Create the common objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "693def8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the Anthropic Claude 3 model-id\n",
    "#model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "# Specify the URL of the data to be used for RAG\n",
    "rag_data_url = \"https://arxiv.org/pdf/2401.15884.pdf\"\n",
    "\n",
    "# Specify the Amazon S3 bucket key prefix\n",
    "# Note: The bucket name will be automatically determined\n",
    "# from the Knowledge Base data source when executing cells\n",
    "# further down in this notebook\n",
    "s3_key_prefix = \"rag_data\"\n",
    "\n",
    "# Specify the name and location of the prompt templates\n",
    "prompt_templates_dir = os.path.join(os.getcwd(), \"prompt_templates\")\n",
    "query_result_relevancy_prompt_template = 'query_result_relevancy_prompt_template.txt'\n",
    "final_prompt_template = 'final_prompt_template.txt'\n",
    "\n",
    "# Specify and create the required output directories\n",
    "rag_data_dir = os.path.join(os.getcwd(), \"rag_data\")\n",
    "os.makedirs(rag_data_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb0a620",
   "metadata": {},
   "source": [
    "###  I. Get Knowledge Base details <a id='Get%20Knowledge%20Base%20details'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2ab613",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> For the purpose of running this notebook, a new Knowledge Base (KB) must be created in the same AWS Region as Amazon Bedrock that was configured in Step 1E of this notebook.\n",
    "<p>This KB must meet the following requirements:\n",
    "    <ul>\n",
    "        <li>KB must be in 'ACTIVE' status.</li>\n",
    "        <li>Must have an Amazon OpenSearch Serverless collection as the vector index.</li>\n",
    "        <li>Must have an Amazon S3 bucket as the data source.</li>\n",
    "        <li>Data source must be in 'AVAILABLE' status.</li>\n",
    "    </ul>\n",
    "</p>\n",
    "<p>During the AIM301 session, by default, a KB that meets all these requirements will be pre-created and ready to use.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a1ddc4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Note:</b> If you are running this notebook outside if the AIM301 session, then, you must create a KB as specified above. Otherwise, this notebook will fail. You can follow the procedure described <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-create.html\">here</a> to create a KB.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62546f06",
   "metadata": {},
   "source": [
    "If you have a created a KB that meets all the requirements mentioned above and want to use it, then enter the id of that KB in the code cell below. If not, this notebook will automatically retrieve the id of the first available KB that meets all the requirements, when you run the cells further down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7367d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_id = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e726d81",
   "metadata": {},
   "source": [
    "Run the following cell to verify the specified KB or to retrieve the first available KB that meets all the requirements. In the process, retreive the S3 bucket name that is set as the data source for this KB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66348062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: 'get_kb_that_meets_requirements' available through ./scripts/helper_functions.py\n",
    "kb_id, ds_id, s3_bucket_name, aoss_collection_arn = get_kb_that_meets_requirements(bedrock_agt_client, kb_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ce9d9",
   "metadata": {},
   "source": [
    "###  J. Get Bedrock Agent details <a id='Get%20Bedrock%20Agent%20details'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4d74ea",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> For the purpose of running this notebook, a new Bedrock Agent along with an agent alias must be created in the same AWS Region as Amazon Bedrock that was configured in Step 1E of this notebook.\n",
    "<p>This agent and it's alias must meet the following requirements:\n",
    "    <ul>\n",
    "        <li>Both the agent and it's alias must be in 'PREPARED' status.</li>\n",
    "    </ul>\n",
    "</p>\n",
    "<p>\n",
    "Although not mandatory, it is strongly recommended to use Anthropic Claude 3 as the LLM for this agent. If you use any other LLM, make sure the model access is enabled by following the instructions mentioned in prior steps.\n",
    "</p>\n",
    "<p>During the AIM301 session, by default, an agent along with it's alias that meet all these requirements will be pre-created and ready to use.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff3532",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Note:</b> If you are running this notebook outside if the AIM301 session, then, you must create a Bedrock Agent along with it's alias as specified above. Otherwise, this notebook will fail. You can follow the procedure described <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/agents-create.html\">here</a> to create a Bedrock Agent and the procedure described <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/agents-alias-manage.html\">here</a> to create an agent alias.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc5d08f",
   "metadata": {},
   "source": [
    "If you have a created a Bedrock Agent and it's alias that meet all the requirements mentioned above and want to use them, then enter their ids in the code cell below. If not, this notebook will automatically retrieve the id of the first available Bedrock Agent and it's alias that meet all the requirements, when you run the cells further down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e85e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_agent_id = ''\n",
    "br_agent_alias_id = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93f9d3",
   "metadata": {},
   "source": [
    "Run the following cell to verify the specified Bedrock Agent (and it's alias) or to retrieve the first available Bedrock Agent (and it's alias) that meet all the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: 'get_br_agent_that_meets_requirements' available through ./scripts/helper_functions.py\n",
    "br_agent_id = get_br_agent_that_meets_requirements(bedrock_agt_client, br_agent_id)\n",
    "if len(br_agent_id) > 0:\n",
    "    # Note: 'get_br_agent_alias_that_meets_requirements' available through ./scripts/helper_functions.py\n",
    "    br_agent_alias_id = get_br_agent_alias_that_meets_requirements(bedrock_agt_client, br_agent_id, br_agent_alias_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a8504",
   "metadata": {},
   "source": [
    "## 2. Load data to Knowledge Base <a id ='Load%20data%20to%20Knowledge%20Base'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ad255",
   "metadata": {},
   "source": [
    "![](./images/load_to_KB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d206d2",
   "metadata": {},
   "source": [
    "###  A. Step 0a: Download data <a id='Load%20to%20KB%20Step0a'></a>\n",
    "\n",
    "Download the data i.e. a LLM whitepaper as a PDF file to a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: 'download_file' available through ./scripts/helper_functions.py\n",
    "downloaded_file_name = download_file(rag_data_url, rag_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a96329",
   "metadata": {},
   "source": [
    "###  B. Step 0b: Copy downloaded data to S3 <a id='Load%20to%20KB%20Step0b'></a>\n",
    "\n",
    "Copy the downloaded PDF file to an Amazon S3 bucket. This bucket will be the [data source](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-ds.html) for the Knowledge Base (KB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70117449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: 'upload_to_s3' available through ./scripts/helper_functions.py\n",
    "upload_to_s3(rag_data_dir, s3_bucket_name, s3_key_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da7f3f",
   "metadata": {},
   "source": [
    "###  C. Steps 0c to 0e: Sync to Knowledge Base <a id='Load%20to%20KB%20Steps0c%20to%200e'></a>\n",
    "\n",
    "Trigger the [sync operation](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-ingest.html) on that Knowledge Base to load the PDF file from that data source (S3) to the [vector index](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-setup.html) configured for that Knowledge Base (KB). In the process of loading, the data will be chunked and converted to vectors using the Embeddings Model specified for that KB. Check the status of the ingestion every 5 seconds until failed or complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d507a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: 'sync_to_kb' available through ./scripts/helper_functions.py\n",
    "sync_to_kb(bedrock_agt_client, ds_id, kb_id, 'Sync PDF from S3 to vector index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7efe68",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> Even if the sync operation is in 'COMPLETE' status, it may take up to 30 seconds for the data to be available for reading from the vector index.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd2c32",
   "metadata": {},
   "source": [
    "## 3. Scenario 1 - match found in KB <a id ='Match%20found%20in%20KB'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c81e4d7",
   "metadata": {},
   "source": [
    "![](./images/scenario_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e027e",
   "metadata": {},
   "source": [
    "###  A. Step 1: User query <a id='Scenario%201%20Step%201'></a>\n",
    "\n",
    "Set the user query along with configurations for the max query results and relevancy score threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a762173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1_query = 'What are hallucinations in LLMs?'\n",
    "max_query_results = 10\n",
    "relevancy_score_threshold = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f1cf22",
   "metadata": {},
   "source": [
    "###  B. Steps 2a and 2b: Query lookup <a id='Scenario%201%20Steps%202a%20and%202b'></a>\n",
    "\n",
    "Perform a semantic search on the vector store in the Knowledge Base (KB) for the user query and retrieve the results. The following cell shows you two ways to do this - one using the LangChain API and the other using the boto3 API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce11ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the LangChain API\n",
    "# Note: 'retrieve_from_kb_using_lc' available through ./scripts/helper_functions.py\n",
    "scenario_1_query_results = retrieve_from_kb_using_lc(bedrock_agt_rt_client, kb_id, scenario_1_query, max_query_results)\n",
    "\n",
    "# Use the boto3 API\n",
    "# Note: 'retrieve_from_kb_using_boto3' available through ./scripts/helper_functions.py\n",
    "#scenario_1_query_results = retrieve_from_kb_using_boto3(bedrock_agt_rt_client, kb_id, scenario_1_query, max_query_results)\n",
    "\n",
    "# Print the retrieval count\n",
    "logging.info(\"Retrieved {} result(s) for the specified query '{}' from the Knowledge Base '{}'.\".format(len(scenario_1_query_results),\n",
    "                                                                                                        scenario_1_query,\n",
    "                                                                                                        kb_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb183e7a",
   "metadata": {},
   "source": [
    "###  C. Steps 3a and 3b: Determine the query results relevancy <a id='Scenario%201%20Steps%203a%20and%203b'></a>\n",
    "\n",
    "For each of the retrieved result, invoke the LLM to determine how relevant the query result is to the user query and capture the results. The following cell uses the LangChain API for invoking the LLM (Anthropic Claude 3 on Amazon Bedrock)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922734d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the LLM to find the relevancy between the query and each retrieved result and capture the response\n",
    "for scenario_1_query_result in scenario_1_query_results:\n",
    "    # Note: 'instruct_llm_to_find_relevancy' available through ./scripts/helper_functions.py\n",
    "    scenario_1_query_result['relevancy_score'] = (instruct_llm_to_find_relevancy(model_id,\n",
    "                                                                                 bedrock_rt_client,\n",
    "                                                                                 prompt_templates_dir,\n",
    "                                                                                 query_result_relevancy_prompt_template,\n",
    "                                                                                 scenario_1_query,\n",
    "                                                                                 scenario_1_query_result['query_result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bdb886",
   "metadata": {},
   "source": [
    "###  D. Steps 4a through 5: Process to completion <a id='Scenario%201%20Steps%204a%20through%205'></a>\n",
    "\n",
    "Determine if at least one of the query results is relevant to the user query based on whether it meets or exceeds the specified relevancy threshold. In scenario 1, it will meet/exceed. So, invoke the LLM (Anthropic Claude 3) using the LangChain API for the final generation and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51066957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the relevancy scores\n",
    "# Note: 'instruct_llm_to_find_correlation' available through ./scripts/helper_functions.py\n",
    "print_results_relevancy_score_stats(scenario_1_query, scenario_1_query_results)\n",
    "\n",
    "# Filter the query results that meet or exceed the specified threshold relevancy score\n",
    "scenario_1_filtered_query_results = filter_query_results_by_threshold(scenario_1_query_results, relevancy_score_threshold)\n",
    "# Check the filtered query results and process\n",
    "if len(scenario_1_filtered_query_results) > 0:\n",
    "    logging.info(\"At least one of the relevancy scores meets or exceeds the specified threshold of '{}'.\".format(relevancy_score_threshold))\n",
    "    # Construct the final prompt with the filtered query results and invoke the LLM\n",
    "    scenario_1_final_response = process_final_prompt(model_id, bedrock_rt_client, prompt_templates_dir,\n",
    "                                                     final_prompt_template, scenario_1_query,\n",
    "                                                     scenario_1_filtered_query_results)\n",
    "else:\n",
    "    logging.warning(\"None of the relevancy scores meets or exceeds the specified threshold of '{}'.\".format(relevancy_score_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f3d66",
   "metadata": {},
   "source": [
    "Print the final response for the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7338ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"\\n\\n{}\\n\\n\".format(scenario_1_final_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e407f02",
   "metadata": {},
   "source": [
    "## 4. Scenario 2 - match not found in KB <a id ='Match%20not%20found%20in%20KB'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c21eeb",
   "metadata": {},
   "source": [
    "![](./images/scenario_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c9feb0",
   "metadata": {},
   "source": [
    "###  A. Step 1: User query <a id='Scenario%202%20Step%201'></a>\n",
    "\n",
    "Set the user query along with configurations for the max query results and relevancy score threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_2_query = 'When is the 2024 Summer Olympics?'\n",
    "max_query_results = 10\n",
    "relevancy_score_threshold = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0125920a",
   "metadata": {},
   "source": [
    "###  B. Steps 2a and 2b: Query lookup <a id='Scenario%202%20Steps%202a%20and%202b'></a>\n",
    "\n",
    "Perform a semantic search on the vector store in the Knowledge Base (KB) for the user query and retrieve the results. The following cell shows you two ways to do this - one using the LangChain API and the other using the boto3 API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b93407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the LangChain API\n",
    "# Note: 'retrieve_from_kb_using_lc' available through ./scripts/helper_functions.py\n",
    "scenario_2_query_results = retrieve_from_kb_using_lc(bedrock_agt_rt_client, kb_id, scenario_2_query, max_query_results)\n",
    "\n",
    "# Use the boto3 API\n",
    "# Note: 'retrieve_from_kb_using_boto3' available through ./scripts/helper_functions.py\n",
    "#scenario_2_query_results = retrieve_from_kb_using_boto3(bedrock_agt_rt_client, kb_id, scenario_2_query, max_query_results)\n",
    "\n",
    "# Print the retrieval count\n",
    "logging.info(\"Retrieved {} result(s) for the specified query '{}' from the Knowledge Base '{}'.\".format(len(scenario_2_query_results),\n",
    "                                                                                                        scenario_2_query,\n",
    "                                                                                                        kb_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b60702",
   "metadata": {},
   "source": [
    "###  C. Steps 3a and 3b: Determine the query results relevancy <a id='Scenario%202%20Steps%203a%20and%203b'></a>\n",
    "\n",
    "For each of the retrieved result, invoke the LLM to determine how relevant the query result is to the user query and capture the results. The following cell uses the LangChain API for invoking the LLM (Anthropic Claude 3 on Amazon Bedrock)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da02cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the LLM to find the relevancy between the query and each retrieved result and capture the response\n",
    "for scenario_2_query_result in scenario_2_query_results:\n",
    "    # Note: 'instruct_llm_to_find_relevancy' available through ./scripts/helper_functions.py\n",
    "    scenario_2_query_result['relevancy_score'] = (instruct_llm_to_find_relevancy(model_id,\n",
    "                                                                                 bedrock_rt_client,\n",
    "                                                                                 prompt_templates_dir,\n",
    "                                                                                 query_result_relevancy_prompt_template,\n",
    "                                                                                 scenario_2_query,\n",
    "                                                                                 scenario_2_query_result['query_result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc319258",
   "metadata": {},
   "source": [
    "###  D. Steps 4a through 7: Process to completion <a id='Scenario%202%20Steps%204a%20through%207'></a>\n",
    "\n",
    "Determine if at least one of the query results is relevant to the user query based on whether it meets or exceeds the specified relevancy threshold. In scenario 2, it will not meet/exceed. So, print a warning and do a web search. Then, use the results from the web search and invoke the LLM for the final generation and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb0c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the relevancy scores\n",
    "# Note: 'instruct_llm_to_find_correlation' available through ./scripts/helper_functions.py\n",
    "print_results_relevancy_score_stats(scenario_2_query, scenario_2_query_results)\n",
    "\n",
    "# Filter the query results that meet or exceed the specified threshold relevancy score\n",
    "scenario_2_filtered_query_results = filter_query_results_by_threshold(scenario_2_query_results, relevancy_score_threshold)\n",
    "# Check the filtered query results and process\n",
    "if len(scenario_2_filtered_query_results) > 0:\n",
    "    logging.info(\"At least one of the relevancy scores meets or exceeds the specified threshold of '{}'.\".format(relevancy_score_threshold))\n",
    "else:\n",
    "    logging.warning(\"None of the relevancy scores meets or exceeds the specified threshold of '{}'.\".format(relevancy_score_threshold))\n",
    "    # Perform web search through Agents for Amazon Bedrock and retrieve the response\n",
    "    scenario_2_final_response = perform_web_search(br_agent_alias_id, br_agent_id, bedrock_agt_rt_client, scenario_2_query)\n",
    "    logging.info(\"Prompt response: {}\".format(scenario_2_final_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb89043",
   "metadata": {},
   "source": [
    "Print the final response for the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db971151",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"\\n\\n{}\\n\\n\".format(scenario_2_final_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1216a",
   "metadata": {},
   "source": [
    "## 5. Cleanup <a id='Cleanup'></a>\n",
    "\n",
    "As a best practice, you should delete AWS resources that are no longer required.  This will help you avoid incurring unncessary costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c018f3f7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> During the AIM301 session, by default, all resources will be cleaned up at the end of the session. If you are running this notebook outside of this session, you can cleanup the resources associated with this notebook by running the following cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb865606",
   "metadata": {},
   "source": [
    "Running the following cell will delete the following resources:\n",
    "* Knowledge Base.\n",
    "* Amazon OpenSearch Serverless Collection.\n",
    "* The file that was uploaded to S3; not the S3 bucket itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6923a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: 'delete_kb' available through ./scripts/helper_functions.py\n",
    "#delete_kb(bedrock_agt_client, kb_id)\n",
    "\n",
    "# Note: 'delete_aoss_collection' available through ./scripts/helper_functions.py\n",
    "#delete_aoss_collection(aoss_client, collection_id)\n",
    "\n",
    "# Note: 'delete_s3_object' available through ./scripts/helper_functions.py\n",
    "delete_s3_object(s3_client, s3_bucket_name, s3_key_prefix + '/' + downloaded_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd52a5",
   "metadata": {},
   "source": [
    "## 6. Conclusion <a id='Conclusion'></a>\n",
    "\n",
    "We have now seen how to build a simplified CRAG based assistant using Amazon Bedrock. This is an advanced RAG technique that works on improving the quality of the retrieved documents prior to the generation process. We have also seen how Amazon Bedrock with its LLMs, Knowledge Bases (KBs) and Agents make it easy for you build generative AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf266cf",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 7. Frequently Asked Questions (FAQs) <a id='FAQs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf2c50f",
   "metadata": {},
   "source": [
    "**Q: What AWS services are used in this notebook?**\n",
    "\n",
    "Amazon Bedrock, AWS Identity and Access Management (IAM), Amazon CloudWatch, and Amazon SageMaker Notebook instance (or) Amazon SageMaker Studio Notebook depending on what you use to run the notebook.\n",
    "\n",
    "**Q: Will Amazon Bedrock capture and store my data?**\n",
    "\n",
    "Amazon Bedrock doesn't use your prompts and continuations to train any AWS models or distribute them to third parties. Your training data isn't used to train the base Amazon Titan models or distributed to third parties. Other usage data, such as usage timestamps, logged account IDs, and other information logged by the service, is also not used to train the models.\n",
    "\n",
    "Amazon Bedrock uses the fine tuning data you provide only for fine tuning an Amazon Titan model. Amazon Bedrock doesn't use fine tuning data for any other purpose, such as training base foundation models.\n",
    "\n",
    "Each model provider has an escrow account that they upload their models to. The Amazon Bedrock inference account has permissions to call these models, but the escrow accounts themselves don't have outbound permissions to Amazon Bedrock accounts. Additionally, model providers don't have access to Amazon Bedrock logs or access to customer prompts and continuations.\n",
    "\n",
    "Amazon Bedrock doesn’t store or log your data in its service logs.\n",
    "\n",
    "**Q: What models are supported by Amazon Bedrock?**\n",
    "\n",
    "Go [here](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html).\n",
    "\n",
    "**Q: What is the difference between On-demand and Provisioned Throughput in Amazon Bedrock?**\n",
    "\n",
    "With the On-Demand mode, you only pay for what you use, with no time-based term commitments. For text generation models, you are charged for every input token processed and every output token generated. For embeddings models, you are charged for every input token processed. A token is comprised of a few characters and refers to the basic unit that a model learns to understand user input and prompt to generate results. For image generation models, you are charged for every image generated.\n",
    "\n",
    "With the Provisioned Throughput mode, you can purchase model units for a specific base or custom model. The Provisioned Throughput mode is primarily designed for large consistent inference workloads that need guaranteed throughput. Custom models can only be accessed using Provisioned Throughput. A model unit provides a certain throughput, which is measured by the maximum number of input or output tokens processed per minute. With this Provisioned Throughput pricing, charged by the hour, you have the flexibility to choose between 1-month or 6-month commitment terms.\n",
    "\n",
    "**Q: Where can I find customer references for Amazon Bedrock?**\n",
    "\n",
    "Go [here](https://aws.amazon.com/bedrock/testimonials/).\n",
    "\n",
    "**Q: Where can I find resources for prompt engineering?**\n",
    "\n",
    "[Prompt Engineering Guide](https://www.promptingguide.ai/).\n",
    "\n",
    "**Q: Where can learn more about Corrective RAG?**\n",
    "\n",
    "Go [here](https://arxiv.org/abs/2401.15884).\n",
    "\n",
    "**Q: Is LangChain mandatory to use Amazon Bedrock?**\n",
    "\n",
    "No. You can interact with Amazon Bedrock using the [Bedrock API](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html) or language-specific [AWS SDKs](https://aws.amazon.com/developer/tools/). \n",
    "\n",
    "**Q: How do I get started with LangChain?**\n",
    "\n",
    "Go [here](https://python.langchain.com/docs/get_started/introduction).\n",
    "\n",
    "**Q: Where can I find pricing information for the AWS services used in this notebook?**\n",
    "\n",
    "- Amazon Bedrock pricing - go [here](https://aws.amazon.com/bedrock/pricing/).\n",
    "- Amazon OpenSearch Serverless pricing - go [here](https://aws.amazon.com/opensearch-service/pricing/) and navigate to the <i>Serverless</i> section.\n",
    "- Amazon S3 pricing - go [here](https://aws.amazon.com/s3/pricing/).\n",
    "- AWS Lambda pricing - go [here](https://aws.amazon.com/lambda/pricing/).\n",
    "- AWS Identity and Access Management (IAM) pricing - free.\n",
    "- Amazon CloudWatch pricing - go [here](https://aws.amazon.com/cloudwatch/pricing/).\n",
    "- Amazon SageMaker Notebook instance (or) Amazon SageMaker Studio Notebook pricing - go [here](https://aws.amazon.com/sagemaker/pricing/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe2e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
